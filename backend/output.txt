crud.py 
from sqlalchemy.orm import Session
from backend import db_models, schemas
from typing import List, Optional

# =====================================================
# USER OPERATIONS
# =====================================================

def get_user_by_username(db: Session, username: str) -> Optional[db_models.User]:
    """Get user by username"""
    return db.query(db_models.User).filter(db_models.User.username == username).first()

def get_user_by_email(db: Session, email: str) -> Optional[db_models.User]:
    """Get user by email"""
    return db.query(db_models.User).filter(db_models.User.email == email).first()

def get_user_by_id(db: Session, user_id: str) -> Optional[db_models.User]:
    """Get user by ID"""
    return db.query(db_models.User).filter(db_models.User.id == user_id).first()

def create_user(db: Session, user: schemas.UserCreate, hashed_password: str) -> db_models.User:
    """Create new user with hashed password"""
    db_user = db_models.User(
        username=user.username,
        email=user.email,
        hashed_password=hashed_password,
        name=user.name or user.username
    )
    db.add(db_user)
    db.commit()
    db.refresh(db_user)
    return db_user

def authenticate_user(db: Session, username: str, password: str):
    """Authenticate user with username and password"""
    from backend.security import verify_password
    
    user = get_user_by_username(db, username)
    if not user:
        return False
    if not verify_password(password, user.hashed_password):
        return False
    return user

# =====================
# FILE OPERATIONS
# =====================

def create_file(db: Session, file: schemas.FileCreate) -> db_models.File:
    """Create new file record"""
    db_file = db_models.File(**file.dict())
    db.add(db_file)
    db.commit()
    db.refresh(db_file)
    return db_file

def get_user_files(
    db: Session, 
    user_id: str, 
    skip: int = 0, 
    limit: int = 20,
    search: Optional[str] = None
) -> List[db_models.File]:
    """Get all files for a user with pagination and optional search"""
    query = db.query(db_models.File).filter(
        db_models.File.user_id == user_id,
        db_models.File.is_deleted == False
    )
    
    if search:
        query = query.filter(
            db_models.File.filename.contains(search) |
            db_models.File.transcript.contains(search)
        )
    
    return query.order_by(db_models.File.created_at.desc()).offset(skip).limit(limit).all()

def get_file_by_id(db: Session, file_id: str, user_id: str) -> Optional[db_models.File]:
    """Get specific file by ID (ensuring it belongs to the user)"""
    return db.query(db_models.File).filter(
        db_models.File.id == file_id,
        db_models.File.user_id == user_id,
        db_models.File.is_deleted == False
    ).first()

def delete_file(db: Session, file_id: str, user_id: str) -> bool:
    """Soft delete a file"""
    file = get_file_by_id(db, file_id, user_id)
    if file:
        file.is_deleted = True
        db.commit()
        return True
    return False

def get_user_file_count(db: Session, user_id: str) -> int:
    """Get total file count for user"""
    return db.query(db_models.File).filter(
        db_models.File.user_id == user_id,
        db_models.File.is_deleted == False
    ).count()

def star_file(db: Session, file_id: str, user_id: str, starred: bool) -> bool:
    """Star/unstar a file"""
    file = get_file_by_id(db, file_id, user_id)
    if file:
        file.is_starred = starred
        db.commit()
        return True
    return False

def pin_file(db: Session, file_id: str, user_id: str, pinned: bool) -> bool:
    """Pin/unpin a file"""
    file = get_file_by_id(db, file_id, user_id)
    if file:
        file.is_pinned = pinned
        db.commit()
        return True
    return False

def get_starred_files(db: Session, user_id: str) -> List[db_models.File]:
    """Get all starred files"""
    return db.query(db_models.File).filter(
        db_models.File.user_id == user_id,
        db_models.File.is_starred == True,
        db_models.File.is_deleted == False
    ).order_by(db_models.File.created_at.desc()).all()
    
def delete_file(db: Session, file_id: str, user_id: str) -> bool:
    """Soft delete a file"""
    file = db.query(db_models.File).filter(
        db_models.File.id == file_id,
        db_models.File.user_id == user_id,
        db_models.File.is_deleted == False
    ).first()
    
    if not file:
        return False
    
    file.is_deleted = True
    db.commit()
    
    return True
database.py 
import os
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from dotenv import load_dotenv

load_dotenv()

# MySQL connection URL
MYSQL_HOST = os.getenv("MYSQL_HOST", "localhost")
MYSQL_PORT = os.getenv("MYSQL_PORT", "3306")
MYSQL_USER = os.getenv("MYSQL_USER", "root")
MYSQL_PASSWORD = os.getenv("MYSQL_PASSWORD")
MYSQL_DATABASE = os.getenv("MYSQL_DATABASE", "transcribeflow")

DATABASE_URL = f"mysql+pymysql://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DATABASE}"

# Create engine
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,  # Check connection before using
    pool_recycle=3600,   # Recycle connections after 1 hour
    echo=False           # Set to True for SQL debugging
)

# Create session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for models
Base = declarative_base()

# Dependency to get DB session
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

db_models.py 
from sqlalchemy import Column, String, Integer, Float, Text, DateTime, ForeignKey, Boolean
from sqlalchemy.sql import func
from backend.database import Base
import uuid

class User(Base):
    __tablename__ = "users"
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    username = Column(String(100), unique=True, nullable=False, index=True)
    email = Column(String(255), unique=True, nullable=False, index=True)
    hashed_password = Column(String(255), nullable=False)
    name = Column(String(255))
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    total_files = Column(Integer, default=0)
    total_minutes = Column(Float, default=0.0)
    is_active = Column(Boolean, default=True)


class File(Base):
    __tablename__ = "files"
    
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    user_id = Column(String(36), ForeignKey("users.id", ondelete="CASCADE"), nullable=False, index=True)
    filename = Column(String(255), nullable=False)
    saved_as = Column(String(500), nullable=False)  # Actual filename on disk
    file_size_mb = Column(Float)
    language = Column(String(10))
    transcript = Column(Text)
    summary = Column(Text)
    audio_url = Column(Text)
    duration_seconds = Column(Float, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now(), index=True)
    is_deleted = Column(Boolean, default=False)
    word_timestamps = Column(Text, nullable=True)
    speaker_segments = Column(Text, nullable=True)
    is_starred = Column(Boolean, default=False)
    is_pinned = Column(Boolean, default=False)
dependencies.py 
from fastapi import Depends, HTTPException, status
from sqlalchemy.orm import Session
from backend.database import get_db
from backend import crud
from backend.security import get_current_user_from_token

def get_current_user(
    token_user_id: str = Depends(get_current_user_from_token),
    db: Session = Depends(get_db)
):
    """
    Dependency to get the current logged-in user from JWT token.
    Raises 401 if not authenticated or user not found.
    """
    user = crud.get_user_by_id(db, token_user_id)
    
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="User not found. Please login again."
        )
    
    if not user.is_active:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Account is inactive"
        )
    
    return user

def get_current_user_optional(db: Session = Depends(get_db)):
    """
    Optional authentication - returns None if not authenticated.
    Does not raise exceptions.
    """
    try:
        from backend.security import oauth2_scheme
        from fastapi import Request
        
        # This is simplified - in practice you'd need to extract token
        return None
    except:
        return None
export.py 
import json
from io import BytesIO
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet
from docx import Document
import pysrt

def export_txt(transcript: str, summary: str, filename: str) -> bytes:
    """Export as plain text"""
    content = f"Transcript: {filename}\n\n"
    content += f"SUMMARY:\n{summary}\n\n"
    content += f"FULL TRANSCRIPT:\n{transcript}"
    return content.encode('utf-8')

def export_pdf(transcript: str, summary: str, filename: str) -> bytes:
    """Export as PDF using reportlab"""
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    story = []
    styles = getSampleStyleSheet()
    
    # Title
    story.append(Paragraph(f"Transcript: {filename}", styles['Title']))
    story.append(Spacer(1, 12))
    
    # Summary
    story.append(Paragraph("SUMMARY:", styles['Heading2']))
    story.append(Paragraph(summary, styles['Normal']))
    story.append(Spacer(1, 12))
    
    # Transcript
    story.append(Paragraph("FULL TRANSCRIPT:", styles['Heading2']))
    story.append(Paragraph(transcript, styles['Normal']))
    
    doc.build(story)
    buffer.seek(0)
    return buffer.read()

def export_docx(transcript: str, summary: str, filename: str) -> bytes:
    """Export as DOCX"""
    doc = Document()
    doc.add_heading(f"Transcript: {filename}", 0)
    
    doc.add_heading("Summary", level=1)
    doc.add_paragraph(summary)
    
    doc.add_heading("Full Transcript", level=1)
    doc.add_paragraph(transcript)
    
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.read()

def export_srt(word_timestamps: str, transcript: str) -> bytes:
    """Export as SRT subtitle format"""
    try:
        words = json.loads(word_timestamps)
        subs = pysrt.SubRipFile()
        
        # Group words into subtitle chunks (every 10 words or 5 seconds)
        chunk_size = 10
        for i in range(0, len(words), chunk_size):
            chunk = words[i:i + chunk_size]
            if not chunk:
                continue
            
            start_ms = int(chunk[0]["start"] * 1000)
            end_ms = int(chunk[-1]["end"] * 1000)
            text = " ".join([w["word"] for w in chunk])
            
            sub = pysrt.SubRipItem(
                index=len(subs) + 1,
                start=pysrt.SubRipTime(milliseconds=start_ms),
                end=pysrt.SubRipTime(milliseconds=end_ms),
                text=text
            )
            subs.append(sub)
        
        return str(subs).encode('utf-8')
    except:
        # Fallback if no timestamps
        return f"1\n00:00:00,000 --> 00:00:10,000\n{transcript[:100]}".encode('utf-8')
main.py 
# Imports and standard libraries
import os
import uuid
import mimetypes
import asyncio
import logging
import pathlib
import json
from datetime import datetime, timedelta
from contextlib import asynccontextmanager
from typing import Optional, List
from io import BytesIO

# FastAPI and related imports
from fastapi import (
    FastAPI,
    UploadFile,
    File,
    Form,
    HTTPException,
    WebSocket,
    WebSocketDisconnect,
    Request,
    Depends,
    BackgroundTasks,
    status
)
from fastapi.staticfiles import StaticFiles
from fastapi.responses import StreamingResponse, RedirectResponse, FileResponse
from fastapi.concurrency import run_in_threadpool
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm

# Backend application modules
from backend.models import pipeline
from backend.database import get_db
from backend import crud, schemas
from backend.dependencies import get_current_user
from backend.export import export_txt, export_pdf, export_docx, export_srt
from backend.security import (
    hash_password,
    verify_password,
    create_access_token,
    ACCESS_TOKEN_EXPIRE_MINUTES
)
from backend.schemas import UserCreate, UserLogin, Token

from sqlalchemy.orm import Session
from pydantic import BaseModel

# Request model for translation
class TranslateRequest(BaseModel):
    text: str
    source_lang: Optional[str] = "auto"
    target_lang: Optional[str] = "en"

# Request model for language detection
class DetectLanguageRequest(BaseModel):
    text: str

# Configure application logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Store active websocket connections
active_connections: dict[str, WebSocket] = {}

# Queue used to send logs to websockets
log_queue: asyncio.Queue = asyncio.Queue()

# Store main event loop reference
main_loop: asyncio.AbstractEventLoop | None = None

# Custom logging handler that forwards logs to websockets
class WebSocketLogHandler(logging.Handler):
    def emit(self, record):
        if record.levelno != logging.INFO or not main_loop:
            return
        try:
            msg = self.format(record)
            main_loop.call_soon_threadsafe(
                log_queue.put_nowait,
                (msg, record.levelname),
            )
        except Exception:
            pass

# Register websocket log handler
ws_handler = WebSocketLogHandler()
ws_handler.setFormatter(logging.Formatter("%(name)s: %(message)s"))
logging.getLogger().addHandler(ws_handler)

# Background task that sends logs to all websocket clients
async def process_log_queue():
    while True:
        msg, level = await log_queue.get()
        dead = []
        for rid, ws in active_connections.items():
            try:
                await ws.send_json({
                    "type": "log",
                    "message": msg,
                    "level": level.lower(),
                    "timestamp": datetime.now().isoformat(),
                })
            except Exception:
                dead.append(rid)
        for rid in dead:
            active_connections.pop(rid, None)

# Application lifespan handler
@asynccontextmanager
async def lifespan(app: FastAPI):
    global main_loop
    main_loop = asyncio.get_running_loop()
    task = asyncio.create_task(process_log_queue())
    yield
    task.cancel()
    active_connections.clear()

# Create Database Tables on Startup
from backend.database import engine, Base
from backend import db_models  # Import models so they're registered

# Create all tables
Base.metadata.create_all(bind=engine)
logger.info("âœ… Database tables created/verified")

# Create FastAPI app
app = FastAPI(
    title="TranscribeFlow",
    version="2.2",
    lifespan=lifespan,
)

# Enable CORS for all origins
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Resolve base directories
BASE_DIR = pathlib.Path(__file__).parent.parent.resolve()
UPLOAD_DIR = str(BASE_DIR / "uploads")
FRONTEND_DIR = str(BASE_DIR / "frontend")
STATIC_DIR = BASE_DIR / "frontend" / "static"

# Ensure required folders exist
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(FRONTEND_DIR, exist_ok=True)

# File validation settings
ALLOWED_EXTENSIONS = {".mp3", ".wav", ".m4a", ".flac", ".ogg"}
MAX_FILE_SIZE = 25 * 1024 * 1024

# Serve static assets (CSS, JS, images)
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

# WebSocket endpoint for live logs
@app.websocket("/ws/logs/{request_id}")
async def websocket_logs(ws: WebSocket, request_id: str):
    await ws.accept()
    active_connections[request_id] = ws
    try:
        while True:
            await ws.receive_text()
    except WebSocketDisconnect:
        pass
    finally:
        active_connections.pop(request_id, None)

# =====================================================
# Authentication Routes
# =====================================================

@app.post("/api/auth/register", response_model=schemas.UserResponse, status_code=201)
async def register(user: UserCreate, db: Session = Depends(get_db)):
    """Register a new user"""
    
    # Check if username already exists
    db_user = crud.get_user_by_username(db, user.username)
    if db_user:
        raise HTTPException(
            status_code=400,
            detail="Username already registered"
        )
    
    # Check if email already exists
    db_user = crud.get_user_by_email(db, user.email)
    if db_user:
        raise HTTPException(
            status_code=400,
            detail="Email already registered"
        )
    
    # Hash password
    hashed_password = hash_password(user.password)
    
    # Create user
    new_user = crud.create_user(db, user, hashed_password)
    
    logger.info(f"âœ… New user registered: {user.username}")
    
    return new_user

@app.post("/api/auth/login", response_model=Token)
async def login(user_credentials: UserLogin, db: Session = Depends(get_db)):
    """Login and get access token"""
    
    # Authenticate user
    user = crud.authenticate_user(db, user_credentials.username, user_credentials.password)
    
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # Create access token
    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user.id},
        expires_delta=access_token_expires
    )
    
    logger.info(f"âœ… User logged in: {user.username}")
    
    return {
        "access_token": access_token,
        "token_type": "bearer"
    }

@app.get("/api/auth/me", response_model=schemas.UserResponse)
async def get_current_user_info(current_user = Depends(get_current_user)):
    """Get current logged-in user info"""
    return current_user

@app.post("/api/auth/logout")
async def logout():
    """Logout (client should delete token)"""
    return {"message": "Successfully logged out. Please delete your token."}

# =====================================================
# File Upload & Processing
# =====================================================

@app.post("/api/upload")
async def upload_audio(
    file: UploadFile = File(...),
    language: str = Form("auto"),
    summary_mode: str = Form("bullet"),
    enable_diarization: str = Form("false"),
    num_speakers: Optional[int] = Form(None),
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user),
):
    """Upload and process audio file"""
    ext = os.path.splitext(file.filename)[1].lower()
    if ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(400, "Unsupported file type")

    content = await file.read()
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(413, "File too large")

    safe_name = f"{uuid.uuid4().hex[:8]}_{file.filename}"
    path = os.path.join(UPLOAD_DIR, safe_name)

    with open(path, "wb") as f:
        f.write(content)

    # Parse diarization flag from string
    diarization_enabled = enable_diarization.lower() in ('true', '1', 'yes', 'on')
    logger.info(f"ðŸ”§ Diarization enabled: {diarization_enabled} (raw value: '{enable_diarization}')")

    # Transcribe
    transcript_result = await run_in_threadpool(pipeline.transcribe, path, language)
    transcript_text = transcript_result["text"]
    word_timestamps = transcript_result["words"]
    transcript_segments = transcript_result.get("segments", [])
    
    logger.info(f"ðŸ“Š Transcription data: {len(word_timestamps)} words, {len(transcript_segments)} segments, {len(transcript_text)} chars")
    
    # Speaker diarization (optional)
    speaker_segments = []
    formatted_transcript = transcript_text  # Default to plain transcript
    
    if diarization_enabled:
        try:
            logger.info("ðŸŽ¤ Running speaker diarization...")
            logger.info(f"ðŸ“‚ Audio file: {path}")
            logger.info(f"ðŸ‘¥ Expected speakers: {num_speakers if num_speakers else 'Auto-detect'}")
            
            # Run diarization and wait for completion
            speaker_segments = await run_in_threadpool(
                pipeline.diarize_speakers,
                path,
                num_speakers
            )
            
            # Log what we got back
            logger.info(f"ðŸ” Diarization returned {len(speaker_segments) if speaker_segments else 0} segments")
            
            # Merge diarization with transcript
            if speaker_segments and len(speaker_segments) > 0:
                # Count unique speakers
                unique_speakers = len(set([s['speaker'] for s in speaker_segments]))
                logger.info(f"ðŸ‘¤ Found {unique_speakers} unique speakers")
                
                # Merge with all available transcript data
                speaker_transcript = pipeline.merge_diarization_with_transcript(
                    word_timestamps,
                    speaker_segments,
                    transcript_segments=transcript_segments,
                    full_text=transcript_text
                )
                
                logger.info(f"ðŸ“ Created {len(speaker_transcript)} speaker turns")
                
                # Format for display
                formatted_transcript = pipeline.format_transcript_with_speakers(speaker_transcript)
                
                logger.info(f"âœ… Diarization complete! Transcript formatted with {unique_speakers} speakers")
            else:
                logger.warning("âš ï¸ No speaker segments returned from diarization")
                logger.warning("âš ï¸ Using original transcript without speaker labels")
            
        except Exception as e:
            logger.error(f"âŒ Diarization failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
            logger.warning("âš ï¸ Continuing with original transcript")
    
    # Summarize (use the formatted transcript if diarization was used)
    summary = await run_in_threadpool(pipeline.summarize, formatted_transcript, summary_mode)
    
    # Save to database
    db_file = crud.create_file(
        db,
        schemas.FileCreate(
            user_id=current_user.id,
            filename=file.filename,
            saved_as=safe_name,
            file_size_mb=round(len(content) / (1024 * 1024), 2),
            language=language,
            transcript=formatted_transcript,  # âœ… Use formatted transcript
            summary=summary,
            audio_url=f"/api/stream/{safe_name}",
            word_timestamps=json.dumps(word_timestamps),
            speaker_segments=json.dumps(speaker_segments) if speaker_segments else None
        ),
    )

    return {
        "id": db_file.id,
        "filename": file.filename,
        "file_size": len(content),  # âœ… Add file size in bytes
        "size": len(content),  # âœ… Add alias
        "file_size_mb": db_file.file_size_mb,  # âœ… Keep MB version
        "audio_url": db_file.audio_url,
        "transcript": db_file.transcript,
        "summary": db_file.summary,
        "language": language,  # âœ… Add language
        "created_at": db_file.created_at.isoformat(),  # âœ… Add timestamp
        "status": "success",
    }

@app.post("/api/upload/batch")
async def batch_upload_audio(
    files: List[UploadFile] = File(...),
    language: str = Form("auto"),
    summary_mode: str = Form("bullet"),
    enable_diarization: str = Form("false"),
    num_speakers: Optional[int] = Form(None),
    background_tasks: BackgroundTasks = None,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Upload multiple files and process them in background"""
    
    if len(files) > 10:
        raise HTTPException(400, "Maximum 10 files per batch")
    
    batch_id = str(uuid.uuid4())
    results = []
    
    for idx, file in enumerate(files):
        request_id = f"{batch_id}_{idx}"
        logger.info(f"ðŸ“¤ Batch upload {idx+1}/{len(files)}: {file.filename}")
        
        # Validate file
        ext = os.path.splitext(file.filename)[1].lower()
        if ext not in ALLOWED_EXTENSIONS:
            results.append({
                "filename": file.filename,
                "status": "error",
                "error": "Unsupported file format"
            })
            continue
        
        content = await file.read()
        if len(content) > MAX_FILE_SIZE:
            results.append({
                "filename": file.filename,
                "status": "error",
                "error": "File too large"
            })
            continue
        
        # Save file
        safe_name = f"{uuid.uuid4().hex[:8]}_{file.filename}"
        save_path = os.path.join(UPLOAD_DIR, safe_name)
        
        with open(save_path, "wb") as f:
            f.write(content)
        
        # Parse diarization flag from string
        diarization_enabled = enable_diarization.lower() in ('true', '1', 'yes', 'on') if isinstance(enable_diarization, str) else bool(enable_diarization)
        
        # Process in background
        background_tasks.add_task(
            process_audio_file,
            save_path,
            safe_name,
            file.filename,
            language,
            summary_mode,
            current_user.id,
            len(content),
            diarization_enabled,
            num_speakers
        )
        
        results.append({
            "filename": file.filename,
            "status": "processing",
            "request_id": request_id
        })
    
    return {
        "batch_id": batch_id,
        "total_files": len(files),
        "results": results
    }

# Background processing function
async def process_audio_file(
    save_path: str,
    safe_name: str,
    filename: str,
    language: str,
    summary_mode: str,
    user_id: str,
    file_size: int,
    enable_diarization = False,
    num_speakers: Optional[int] = None
):
    """Background task to process audio file"""
    from backend.database import SessionLocal
    
    # Ensure enable_diarization is a boolean
    if isinstance(enable_diarization, str):
        enable_diarization = enable_diarization.lower() in ('true', '1', 'yes', 'on')
    
    db = SessionLocal()
    try:
        logger.info(f"ðŸŽ™ï¸ Processing {filename}...")
        
        # Transcribe
        transcript_result = pipeline.transcribe(save_path, language)
        transcript_text = transcript_result["text"]
        word_timestamps = transcript_result["words"]
        transcript_segments = transcript_result.get("segments", [])
        
        # Speaker diarization (optional)
        speaker_segments = []
        formatted_transcript = transcript_text
        
        if enable_diarization:
            try:
                speaker_segments = pipeline.diarize_speakers(save_path, num_speakers)
                
                if speaker_segments:
                    speaker_transcript = pipeline.merge_diarization_with_transcript(
                        word_timestamps,
                        speaker_segments,
                        transcript_segments=transcript_segments,
                        full_text=transcript_text
                    )
                    formatted_transcript = pipeline.format_transcript_with_speakers(speaker_transcript)
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Diarization failed for {filename}: {e}")
        
        # Summarize
        summary = pipeline.summarize(formatted_transcript, summary_mode)
        
        # Save to DB
        file_create = schemas.FileCreate(
            user_id=user_id,
            filename=filename,
            saved_as=safe_name,
            file_size_mb=round(file_size / (1024 * 1024), 2),
            language=language,
            transcript=formatted_transcript,
            summary=summary,
            audio_url=f"/api/stream/{safe_name}",
            word_timestamps=json.dumps(word_timestamps),
            speaker_segments=json.dumps(speaker_segments) if speaker_segments else None
        )
        
        db_file = crud.create_file(db, file_create)
        
        logger.info(f"âœ… Completed: {filename}")
    
    except Exception as e:
        logger.error(f"âŒ Failed {filename}: {e}")
    
    finally:
        db.close()

# =====================================================
# Audio Streaming
# =====================================================

@app.get("/api/stream/{filename}")
async def stream_audio(filename: str, request: Request):
    """Stream audio file with Range support for seeking"""
    path = os.path.join(UPLOAD_DIR, filename)
    if not os.path.exists(path):
        raise HTTPException(404, "File not found")

    file_size = os.path.getsize(path)
    mime, _ = mimetypes.guess_type(path)
    mime = mime or "audio/mpeg"

    # Get Range header
    range_header = request.headers.get("range")

    if not range_header:
        # No range requested, send entire file
        def iterator():
            with open(path, "rb") as f:
                yield from f

        return StreamingResponse(
            iterator(),
            media_type=mime,
            headers={
                "Accept-Ranges": "bytes",
                "Content-Length": str(file_size),
            }
        )

    # Parse range header (format: "bytes=start-end")
    try:
        range_str = range_header.replace("bytes=", "")
        range_parts = range_str.split("-")
        
        start = int(range_parts[0]) if range_parts[0] else 0
        end = int(range_parts[1]) if range_parts[1] else file_size - 1
        
        # Validate range
        if start >= file_size or end >= file_size or start > end:
            raise HTTPException(416, "Range Not Satisfiable")
        
        content_length = end - start + 1

        def ranged_iterator():
            with open(path, "rb") as f:
                f.seek(start)
                remaining = content_length
                chunk_size = 8192
                
                while remaining > 0:
                    chunk = f.read(min(chunk_size, remaining))
                    if not chunk:
                        break
                    remaining -= len(chunk)
                    yield chunk

        return StreamingResponse(
            ranged_iterator(),
            status_code=206,  # Partial Content
            media_type=mime,
            headers={
                "Content-Range": f"bytes {start}-{end}/{file_size}",
                "Accept-Ranges": "bytes",
                "Content-Length": str(content_length),
            }
        )
    
    except (ValueError, IndexError):
        raise HTTPException(400, "Invalid Range header")

# =====================================================
# Translation & Language Detection
# =====================================================

@app.post("/api/detect-language")
async def detect_language(req: DetectLanguageRequest):
    """Detect language of text"""
    lang = await run_in_threadpool(pipeline.detect_language, req.text)
    return {"language": lang}

@app.post("/api/translate")
async def translate_text(req: TranslateRequest):
    """Translate text between languages"""
    result = await run_in_threadpool(
        pipeline.translate_text,
        req.text,
        req.source_lang,
        req.target_lang,
    )
    return {"status": "success", **result}

# =====================================================
# File Management
# =====================================================

@app.get("/api/files")
async def get_user_files(
    skip: int = 0,
    limit: int = 100,
    search: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Get all files for the current user with pinned files first"""
    query = db.query(db_models.File).filter(
        db_models.File.user_id == current_user.id,
        db_models.File.is_deleted == False
    )
    
    if search:
        query = query.filter(
            db_models.File.filename.contains(search) |
            db_models.File.transcript.contains(search)
        )
    
    # Sort by pinned first, then by created date
    files = query.order_by(
        db_models.File.is_pinned.desc(),
        db_models.File.created_at.desc()
    ).offset(skip).limit(limit).all()
    
    total = crud.get_user_file_count(db, current_user.id)
    
    return {
        "files": [
            {
                "id": f.id,
                "filename": f.filename,
                "file_size": int(f.file_size_mb * 1024 * 1024) if f.file_size_mb else 0,  # âœ… Add in bytes
                "size": int(f.file_size_mb * 1024 * 1024) if f.file_size_mb else 0,  # âœ… Add alias
                "file_size_mb": f.file_size_mb,
                "size_mb": f.file_size_mb,  # âœ… Add alias
                "language": f.language,
                "created_at": f.created_at.isoformat(),
                "audio_url": f.audio_url,
                "transcript": f.transcript,
                "summary": f.summary,
                "is_starred": f.is_starred,
                "is_pinned": f.is_pinned
            }
            for f in files
        ],
        "total": total,
        "skip": skip,
        "limit": limit
    }

@app.get("/api/files/{file_id}")
async def get_file(
    file_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Get a single file by ID"""
    file = crud.get_file_by_id(db, file_id, current_user.id)
    
    if not file:
        raise HTTPException(404, "File not found")
    
    # Calculate file size in bytes from MB
    file_size_bytes = int(file.file_size_mb * 1024 * 1024) if file.file_size_mb else 0
    
    return {
        "id": file.id,
        "filename": file.filename,
        "file_size": file_size_bytes,  # âœ… Add this - in bytes
        "size": file_size_bytes,  # âœ… Add this alias
        "file_size_mb": file.file_size_mb,  # Keep for backwards compatibility
        "size_mb": file.file_size_mb,  # âœ… Add this alias
        "language": file.language,
        "created_at": file.created_at.isoformat(),
        "audio_url": file.audio_url,
        "transcript": file.transcript,
        "summary": file.summary,
        "is_starred": file.is_starred,
        "is_pinned": file.is_pinned,
        "word_timestamps": file.word_timestamps,
        "speaker_segments": file.speaker_segments
    }

@app.delete("/api/files/{file_id}")
async def delete_file(
    file_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Delete a file (soft delete)"""
    success = crud.delete_file(db, file_id, current_user.id)
    
    if not success:
        raise HTTPException(404, "File not found")
    
    return {"message": "File deleted successfully"}

@app.patch("/api/files/{file_id}/star")
async def star_file(
    file_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Star/unstar a file"""
    from pydantic import BaseModel
    
    class StarRequest(BaseModel):
        starred: bool
    
    # Get request body
    request = await Request.json()
    starred = request.get('starred', False)
    
    success = crud.star_file(db, file_id, current_user.id, starred)
    
    if not success:
        raise HTTPException(404, "File not found")
    
    return {"message": "File starred" if starred else "File unstarred"}

@app.patch("/api/files/{file_id}/pin")
async def pin_file(
    file_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Pin/unpin a file"""
    from pydantic import BaseModel
    
    class PinRequest(BaseModel):
        pinned: bool
    
    # Get request body
    request = await Request.json()
    pinned = request.get('pinned', False)
    
    success = crud.pin_file(db, file_id, current_user.id, pinned)
    
    if not success:
        raise HTTPException(404, "File not found")
    
    return {"message": "File pinned" if pinned else "File unpinned"}

@app.get("/api/files/starred")
async def get_starred_files(
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Get all starred files"""
    files = crud.get_starred_files(db, current_user.id)
    
    return {
        "files": [
            {
                "id": f.id,
                "filename": f.filename,
                "is_starred": f.is_starred,
                "is_pinned": f.is_pinned,
                "created_at": f.created_at.isoformat()
            }
            for f in files
        ]
    }

# =====================================================
# Export
# =====================================================

@app.get("/api/files/{file_id}/export")
async def export_file(
    file_id: str,
    format: str,  # txt, pdf, docx, or srt
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Export transcript in various formats"""
    file = crud.get_file_by_id(db, file_id, current_user.id)
    
    if not file:
        raise HTTPException(404, "File not found")
    
    format = format.lower()
    
    if format == "txt":
        content = export_txt(file.transcript, file.summary, file.filename)
        media_type = "text/plain"
        extension = "txt"
    elif format == "pdf":
        content = export_pdf(file.transcript, file.summary, file.filename)
        media_type = "application/pdf"
        extension = "pdf"
    elif format == "docx":
        content = export_docx(file.transcript, file.summary, file.filename)
        media_type = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        extension = "docx"
    elif format == "srt":
        content = export_srt(file.word_timestamps or "[]", file.transcript)
        media_type = "application/x-subrip"
        extension = "srt"
    else:
        raise HTTPException(400, "Invalid format. Use: txt, pdf, docx, or srt")
    
    filename = f"{file.filename.rsplit('.', 1)[0]}.{extension}"
    
    return StreamingResponse(
        BytesIO(content),
        media_type=media_type,
        headers={"Content-Disposition": f"attachment; filename={filename}"}
    )

# =====================================================
# Health Check
# =====================================================

@app.get("/api/health")
async def health():
    """Health check endpoint"""
    return {"status": "ok", "version": "2.2"}

# =====================================================
# Frontend Routes (No Auth Check)
# =====================================================

@app.get("/")
async def serve_index():
    """Serve landing page"""
    file_path = os.path.join(FRONTEND_DIR, "index.html")
    return FileResponse(file_path)

@app.get("/login")
async def serve_login():
    """Serve login page"""
    file_path = os.path.join(FRONTEND_DIR, "login.html")
    return FileResponse(file_path)

@app.get("/register")
async def serve_register():
    """Serve registration page"""
    file_path = os.path.join(FRONTEND_DIR, "register.html")
    return FileResponse(file_path)

@app.get("/upload")
async def serve_upload():
    """Serve upload page"""
    file_path = os.path.join(FRONTEND_DIR, "upload.html")
    return FileResponse(file_path)

@app.get("/dashboard")
async def serve_dashboard():
    """Serve dashboard page"""
    file_path = os.path.join(FRONTEND_DIR, "dashboard.html")
    return FileResponse(file_path)

@app.get("/results")
async def serve_results():
    """Serve results page"""
    file_path = os.path.join(FRONTEND_DIR, "results.html")
    return FileResponse(file_path)
models.py 
# Imports
import os
import logging
import tempfile
import warnings
import requests

from groq import Groq
from deep_translator import GoogleTranslator
from langdetect import detect
from dotenv import load_dotenv
from pyannote.audio import Pipeline as DiarizationPipeline

# Global setup
warnings.filterwarnings("ignore", category=UserWarning)
load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# Transcription, summarization, and translation pipeline
class TranscribeFlowPipeline:

    # Initialize API clients and cache
    def __init__(self):
        logger.info("ðŸš€ Initializing TranscribeFlowPipeline...")

        self.groq_key = os.getenv("GROQ_API_KEY")
        if not self.groq_key:
            raise ValueError("Missing GROQ_API_KEY")
        self.groq_client = Groq(api_key=self.groq_key)

        self.hf_key = os.getenv("HUGGINGFACE_TOKEN")
        if not self.hf_key:
            raise ValueError("Missing HUGGINGFACE_TOKEN")
        self.hf_headers = {"Authorization": f"Bearer {self.hf_key}"}
        self.hf_api_url = "https://api-inference.huggingface.co/models/facebook/bart-large-cnn"

        self.translation_cache = {}
        logger.info("ðŸŽ¯ Pipeline initialized\n")


    # Audio transcription with timestamps
    def transcribe(self, audio_input, language="en") -> dict:
        logger.info(f"ðŸŽ™ï¸ Transcribing (lang={language})...")
        try:
            # File path
            if isinstance(audio_input, str):
                if not os.path.exists(audio_input):
                    raise FileNotFoundError(audio_input)
                with open(audio_input, "rb") as f:
                    result = self.groq_client.audio.transcriptions.create(
                        file=f,
                        model="whisper-large-v3-turbo",
                        language=language,
                        response_format="verbose_json",
                        timestamp_granularities=["word", "segment"],
                        temperature=0
                    )
            
            # Bytes
            elif isinstance(audio_input, (bytes, bytearray)):
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp:
                    temp.write(audio_input)
                    temp_path = temp.name
                try:
                    with open(temp_path, "rb") as f:
                        result = self.groq_client.audio.transcriptions.create(
                            file=f,
                            model="whisper-large-v3-turbo",
                            language=language,
                            response_format="verbose_json",
                            timestamp_granularities=["word", "segment"],
                            temperature=0
                        )
                finally:
                    os.remove(temp_path)
            else:
                raise TypeError("Unsupported audio format")

            # Extract text and word-level timestamps
            text = result.text.strip()
            words = []
            if hasattr(result, 'words') and result.words:
                for word in result.words:
                    words.append({
                        "word": word.get('word', '') if isinstance(word, dict) else getattr(word, 'word', ''),
                        "start": word.get('start', 0) if isinstance(word, dict) else getattr(word, 'start', 0),
                        "end": word.get('end', 0) if isinstance(word, dict) else getattr(word, 'end', 0),
                    })
            
            # Also extract segment-level timestamps as fallback
            segments = []
            if hasattr(result, 'segments') and result.segments:
                for seg in result.segments:
                    segments.append({
                        "text": seg.get('text', '') if isinstance(seg, dict) else getattr(seg, 'text', ''),
                        "start": seg.get('start', 0) if isinstance(seg, dict) else getattr(seg, 'start', 0),
                        "end": seg.get('end', 0) if isinstance(seg, dict) else getattr(seg, 'end', 0),
                    })
            
            logger.info(f"âœ… Transcription complete â€” {len(words)} words, {len(segments)} segments")
            return {
                "text": text,
                "words": words,
                "segments": segments
            }
        
        except Exception as e:
            logger.error(f"âŒ Transcription failed: {e}")
            raise

    # Clean and normalize LLM output to prevent encoding issues
    def _clean_llm_output(self, text: str) -> str:
        """Clean and normalize LLM output to prevent encoding issues."""
        # Replace Unicode bullets/dashes with ASCII equivalents
        replacements = {
            '\u2022': '* ',  # bullet
            '\u25cf': '* ',  # black circle
            '\u25cb': '* ',  # white circle
            '\u25e6': '* ',  # white bullet
            '\u25aa': '* ',  # black small square
            '\u25b8': '* ',  # right triangle
            '\u2013': '- ',  # en-dash
            '\u2014': '- ',  # em-dash
            '\u2026': '...',  # ellipsis
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        # Fix garbled UTF-8 sequences that appear in some environments
        garbled = {
            '\u00e2\u20ac\u00a2': '* ',
            '\u00e2\u20ac\u201c': '- ',
            '\u00e2\u20ac\u201d': '- ',
            '\u00e2\u0080\u00a2': '* ',
        }
        
        for old, new in garbled.items():
            text = text.replace(old, new)
        
        # Ensure clean UTF-8 encoding
        text = text.encode('utf-8', errors='ignore').decode('utf-8')
        
        return text

    # Transcript summarization
    def summarize(self, text: str, mode: str = "bullet", max_tokens=1024) -> str:
        """
        Summarize with different modes:
        - bullet: Bullet points (default)
        - meeting: Meeting minutes
        - action: Action items
        - study: Study notes
        - blog: Blog-ready summary
        """
        logger.info(f"ðŸ“ Summarizing in '{mode}' mode (text length: {len(text)} chars)...")
        
        # Define prompts for each mode
        prompts = {
            "bullet": "You summarize transcripts into clear, complete bullet points covering ALL key topics. Use markdown bullet format (* item). Every bullet point MUST be a complete sentence. Do NOT cut off mid-sentence.",
            "meeting": "You create professional meeting minutes with sections: Attendees, Discussion Points, Decisions Made, Next Steps.",
            "action": "You extract actionable items and tasks from transcripts in a numbered list.",
            "study": "You create detailed study notes with key concepts, definitions, and important points organized by topic.",
            "blog": "You write an engaging blog post summary with introduction, main points, and conclusion."
        }
        
        system_prompt = prompts.get(mode, prompts["bullet"])
        
        # For very long transcripts, use chunked summarization
        max_input_chars = 16000  # Llama 3.1 8B supports 128K context
        
        if len(text) > max_input_chars:
            return self._summarize_chunked(text, mode, system_prompt, max_tokens, max_input_chars)
        
        return self._summarize_single(text, mode, system_prompt, max_tokens)
    
    def _summarize_single(self, text: str, mode: str, system_prompt: str, max_tokens: int) -> str:
        """Summarize a single chunk of text."""
        try:
            completion = self.groq_client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": f"Summarize this transcript completely. Make sure every point is a full, complete sentence:\n\n{text}"
                    }
                ],
                temperature=0,
                max_tokens=max_tokens
            )
            
            summary = completion.choices[0].message.content.strip()
            
            # Clean encoding artifacts from LLM output
            summary = self._clean_llm_output(summary)
            
            # Format based on mode
            if mode == "bullet" and "*" not in summary and "-" not in summary:
                lines = summary.split(".")
                summary = "\n".join([f"* {l.strip()}" for l in lines if l.strip() and len(l.strip()) > 5])
                return "**Key Points:**\n" + summary
            elif mode == "action" and not summary.startswith("1."):
                lines = [l.strip() for l in summary.split("\n") if l.strip()]
                summary = "\n".join([f"{i+1}. {l}" for i, l in enumerate(lines)])
                return "**Action Items:**\n" + summary
            
            return summary
        
        except Exception as e:
            logger.warning(f"Groq failed â†’ using HF: {e}")
            return self._summarize_hf(text, max_tokens)
    
    def _summarize_chunked(self, text: str, mode: str, system_prompt: str, max_tokens: int, max_input_chars: int) -> str:
        """Summarize long text by splitting into chunks, summarizing each, then combining."""
        logger.info(f"ðŸ“„ Text too long ({len(text)} chars), using chunked summarization...")
        
        # Split text into chunks at sentence boundaries
        chunks = []
        remaining = text
        while remaining:
            if len(remaining) <= max_input_chars:
                chunks.append(remaining)
                break
            # Find last sentence boundary before the limit
            cut_point = remaining[:max_input_chars].rfind('. ')
            if cut_point == -1:
                cut_point = max_input_chars
            else:
                cut_point += 2  # Include the period and space
            chunks.append(remaining[:cut_point])
            remaining = remaining[cut_point:]
        
        logger.info(f"ðŸ“„ Split into {len(chunks)} chunks for summarization")
        
        # Summarize each chunk
        chunk_summaries = []
        for i, chunk in enumerate(chunks):
            logger.info(f"ðŸ“ Summarizing chunk {i+1}/{len(chunks)}...")
            try:
                summary = self._summarize_single(chunk, mode, system_prompt, max_tokens)
                chunk_summaries.append(summary)
            except Exception as e:
                logger.warning(f"Chunk {i+1} failed: {e}")
                continue
        
        if not chunk_summaries:
            return "Summary generation failed."
        
        if len(chunk_summaries) == 1:
            return chunk_summaries[0]
        
        # Combine chunk summaries into a final summary
        combined = "\n\n".join(chunk_summaries)
        logger.info(f"ðŸ“ Combining {len(chunk_summaries)} chunk summaries into final summary...")
        
        try:
            completion = self.groq_client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": f"Combine these partial summaries into one comprehensive, well-organized summary. Make sure every point is a complete sentence:\n\n{combined}"
                    }
                ],
                temperature=0,
                max_tokens=max_tokens
            )
            
            return self._clean_llm_output(completion.choices[0].message.content.strip())
        
        except Exception as e:
            logger.warning(f"Final combination failed, returning merged chunks: {e}")
            return combined



    # Hugging Face fallback summarization
    def _summarize_hf(self, text, max_tokens):
        payload = {
            "inputs": text[:4096],
            "parameters": {"max_length": max_tokens, "min_length": 30, "do_sample": False}
        }

        r = requests.post(
            self.hf_api_url,
            headers=self.hf_headers,
            json=payload,
            timeout=30
        )

        if r.status_code != 200:
            raise RuntimeError("HF summarization failed")

        data = r.json()
        if not data:
            raise RuntimeError("Empty HF response")

        summary = self._clean_llm_output(data[0]["summary_text"])
        return "**Key Points:**\n* " + summary.replace(". ", ".\n* ")


    # Language detection
    def detect_language(self, text: str) -> dict:
        try:
            code = detect(text)
            names = {
                "en": "English",
                "hi": "Hindi",
                "fr": "French",
                "de": "German",
                "es": "Spanish",
                "ru": "Russian",
                "ja": "Japanese",
                "ar": "Arabic",
                "zh-cn": "Chinese"
            }
            return {"code": code, "name": names.get(code, code)}
        except:
            return {"code": "en", "name": "English"}


    # Text translation with caching and fallbacks
    def translate_text(self, text: str, source_lang="auto", target_lang="en") -> dict:
        try:
            cache_key = (text, source_lang, target_lang)
            if cache_key in self.translation_cache:
                return self.translation_cache[cache_key]

            if source_lang == "auto":
                detected = self.detect_language(text)
                source_lang = detected["code"]

            if source_lang == target_lang:
                result = {
                    "original": text,
                    "translated": text,
                    "source_lang": source_lang,
                    "target_lang": target_lang,
                    "success": True
                }
                self.translation_cache[cache_key] = result
                return result

            if source_lang == "hi" or target_lang == "hi":
                translated = self._google_translate(text, source_lang, target_lang)
                result = self._build_result(text, translated, source_lang, target_lang)
                self.translation_cache[cache_key] = result
                return result

            try:
                translated = self._groq_translate(text, source_lang, target_lang)
            except Exception:
                translated = self._google_translate(text, source_lang, target_lang)

            result = self._build_result(text, translated, source_lang, target_lang)
            self.translation_cache[cache_key] = result
            return result

        except Exception as e:
            return {
                "original": text,
                "translated": text,
                "success": False,
                "error": str(e)
            }


    # Groq-based translation helper
    def _groq_translate(self, text, src, tgt):
        names = {
            "en": "English",
            "hi": "Hindi",
            "fr": "French",
            "de": "German",
            "es": "Spanish",
            "ru": "Russian",
            "ja": "Japanese",
            "ar": "Arabic",
            "zh-cn": "Chinese"
        }

        prompt = f"""
Translate the following {names.get(src, src)} text to {names.get(tgt, tgt)}.
Only return the translation.

Text:
{text[:2000]}
"""

        completion = self.groq_client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            max_tokens=1000
        )

        return completion.choices[0].message.content.strip()


    # Google Translate helper with chunking
    def _google_translate(self, text, src, tgt):
        translator = GoogleTranslator(source=src, target=tgt)
        max_len = 4000

        if len(text) <= max_len:
            return translator.translate(text)

        chunks = [text[i:i + max_len] for i in range(0, len(text), max_len)]
        results = [translator.translate(chunk) for chunk in chunks]
        return " ".join(results)


    # Standardized translation result builder
    def _build_result(self, orig, trans, src, tgt):
        return {
            "original": orig,
            "translated": trans,
            "source_lang": src,
            "target_lang": tgt,
            "success": True
        }

    def diarize_speakers(self, audio_path: str, num_speakers: int = None) -> list:
        """
        Detect different speakers in audio
        Returns: List of {speaker, start, end, text} segments
        """
        try:
            logger.info("ðŸ‘¥ Detecting speakers...")
            
            # Check for HuggingFace token
            hf_token = os.getenv("HUGGINGFACE_TOKEN") or os.getenv("HUGGINGFACE_API_KEY")
            if not hf_token:
                raise ValueError("Missing HUGGINGFACE_TOKEN or HUGGINGFACE_API_KEY in .env")
            
            # âœ… NEW: Preprocess audio to fix sampling issues
            import torchaudio
            import torch
            
            # Load audio
            waveform, sample_rate = torchaudio.load(audio_path)
            
            # Resample to 16kHz if needed (pyannote expects 16kHz)
            if sample_rate != 16000:
                logger.info(f"ðŸ”„ Resampling from {sample_rate}Hz to 16000Hz...")
                resampler = torchaudio.transforms.Resample(sample_rate, 16000)
                waveform = resampler(waveform)
                sample_rate = 16000
            
            # Convert to mono if stereo
            if waveform.shape[0] > 1:
                logger.info("ðŸ”„ Converting to mono...")
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            # Save preprocessed audio to temp file
            base, ext = os.path.splitext(audio_path)
            temp_audio = f"{base}_preprocessed.wav"
            torchaudio.save(temp_audio, waveform, sample_rate)
            
            logger.info("âœ… Audio preprocessed for diarization")
            
            # Load diarization pipeline
            diarization_pipeline = DiarizationPipeline.from_pretrained(
                "pyannote/speaker-diarization-3.1",
                token=hf_token
            )
            
            # Run diarization on preprocessed audio
            if num_speakers:
                logger.info(f"ðŸŽ¯ Running diarization with {num_speakers} speakers...")
                diarization_output = diarization_pipeline(temp_audio, num_speakers=num_speakers)
            else:
                logger.info("ðŸŽ¯ Running diarization (auto-detect speakers)...")
                diarization_output = diarization_pipeline(temp_audio)
            
            # Handle different return types from pyannote versions
            # pyannote 3.1+ returns DiarizeOutput dataclass, older versions return Annotation
            if hasattr(diarization_output, 'speaker_diarization'):
                # New pyannote 3.1+ DiarizeOutput dataclass
                logger.info("ðŸ“¦ Extracting annotation from DiarizeOutput...")
                annotation = diarization_output.speaker_diarization
            elif hasattr(diarization_output, 'itertracks'):
                # Legacy: direct Annotation object
                annotation = diarization_output
            else:
                raise TypeError(f"Unexpected diarization output type: {type(diarization_output)}")
            
            # Extract speaker segments from the Annotation
            segments = []
            for turn, _, speaker in annotation.itertracks(yield_label=True):
                segments.append({
                    "speaker": speaker,
                    "start": round(turn.start, 2),
                    "end": round(turn.end, 2)
                })
            
            # Clean up temp file
            try:
                os.remove(temp_audio)
            except:
                pass
            
            num_speakers_found = len(set([s['speaker'] for s in segments]))
            logger.info(f"âœ… Found {num_speakers_found} speakers in {len(segments)} segments")
            
            return segments
        
        except Exception as e:
            logger.error(f"âŒ Diarization failed: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
        
    def merge_diarization_with_transcript(self, transcript_words, speaker_segments, transcript_segments=None, full_text=""):
        """
        Merge speaker diarization with transcript.
        Supports word-level, segment-level, or raw text fallback.
        
        Args:
            transcript_words: list of {word, start, end} from Whisper (may be empty)
            speaker_segments: list of {speaker, start, end} from diarization
            transcript_segments: list of {text, start, end} from Whisper segments (fallback)
            full_text: raw transcript text (final fallback)
        """
        if not speaker_segments:
            return []
        
        import json
        if isinstance(speaker_segments, str):
            speaker_segments = json.loads(speaker_segments)
        
        # Strategy 1: Word-level timestamps (most precise)
        if transcript_words and len(transcript_words) > 0:
            logger.info(f"ðŸ“ Merging using {len(transcript_words)} word-level timestamps")
            return self._merge_with_words(transcript_words, speaker_segments)
        
        # Strategy 2: Segment-level timestamps (good fallback)
        if transcript_segments and len(transcript_segments) > 0:
            logger.info(f"ðŸ“ Merging using {len(transcript_segments)} segment-level timestamps")
            return self._merge_with_segments(transcript_segments, speaker_segments)
        
        # Strategy 3: Raw text splitting (last resort)
        if full_text:
            logger.info("ðŸ“ Merging using raw text splitting (no timestamps available)")
            return self._merge_with_text(full_text, speaker_segments)
        
        logger.warning("âš ï¸ No transcript data available for merge")
        return []
    
    def _merge_with_words(self, transcript_words, speaker_segments):
        """Merge using word-level timestamps (most precise)."""
        # Assign speakers to words based on timestamps
        for word in transcript_words:
            word_start = word.get('start', 0)
            word_end = word.get('end', 0)
            word_mid = (word_start + word_end) / 2
            
            # Find which speaker is talking during this word
            for segment in speaker_segments:
                seg_start = segment.get('start', 0)
                seg_end = segment.get('end', 0)
                
                if seg_start <= word_mid <= seg_end:
                    word['speaker'] = segment.get('speaker', 'UNKNOWN')
                    break
        
        return self._group_by_speaker(transcript_words, key='word')
    
    def _merge_with_segments(self, transcript_segments, speaker_segments):
        """Merge using segment-level timestamps."""
        result_words = []
        for seg in transcript_segments:
            seg_start = seg.get('start', 0)
            seg_end = seg.get('end', 0)
            seg_mid = (seg_start + seg_end) / 2
            text = seg.get('text', '').strip()
            
            if not text:
                continue
            
            # Find the speaker for this segment
            assigned_speaker = 'UNKNOWN'
            best_overlap = 0
            
            for sp_seg in speaker_segments:
                sp_start = sp_seg.get('start', 0)
                sp_end = sp_seg.get('end', 0)
                
                # Calculate overlap
                overlap_start = max(seg_start, sp_start)
                overlap_end = min(seg_end, sp_end)
                overlap = max(0, overlap_end - overlap_start)
                
                if overlap > best_overlap:
                    best_overlap = overlap
                    assigned_speaker = sp_seg.get('speaker', 'UNKNOWN')
            
            result_words.append({
                'word': text,
                'speaker': assigned_speaker,
                'start': seg_start,
                'end': seg_end
            })
        
        return self._group_by_speaker(result_words, key='word')
    
    def _merge_with_text(self, full_text, speaker_segments):
        """Fallback: assign text proportionally to speakers by time."""
        if not full_text.strip():
            return []
        
        # Sort speaker segments by start time
        sorted_segs = sorted(speaker_segments, key=lambda s: s.get('start', 0))
        
        # Calculate total duration
        total_duration = max(s.get('end', 0) for s in sorted_segs) if sorted_segs else 1
        
        # Split text into sentences
        sentences = [s.strip() for s in full_text.replace('? ', '?|').replace('. ', '.|').replace('! ', '!|').split('|') if s.strip()]
        
        if not sentences:
            sentences = [full_text]
        
        # Assign sentences to speaker segments proportionally
        result = []
        current_speaker = None
        current_text = []
        
        chars_per_second = len(full_text) / total_duration if total_duration > 0 else 1
        char_position = 0
        
        for sentence in sentences:
            # Estimate the time position of this sentence
            time_pos = char_position / chars_per_second if chars_per_second > 0 else 0
            char_position += len(sentence)
            
            # Find which speaker is at this time position
            speaker = sorted_segs[0].get('speaker', 'UNKNOWN') if sorted_segs else 'UNKNOWN'
            for seg in sorted_segs:
                if seg.get('start', 0) <= time_pos <= seg.get('end', 0):
                    speaker = seg.get('speaker', 'UNKNOWN')
                    break
            
            if speaker != current_speaker:
                if current_text:
                    result.append({
                        'speaker': current_speaker,
                        'text': ' '.join(current_text).strip()
                    })
                current_speaker = speaker
                current_text = [sentence]
            else:
                current_text.append(sentence)
        
        if current_text:
            result.append({
                'speaker': current_speaker,
                'text': ' '.join(current_text).strip()
            })
        
        return result
    
    def _group_by_speaker(self, items, key='word'):
        """Group consecutive items by speaker into speaker turns."""
        formatted_transcript = []
        current_speaker = None
        current_text = []
        
        for item in items:
            speaker = item.get('speaker', 'UNKNOWN')
            text = item.get(key, item.get('text', ''))
            
            if speaker != current_speaker:
                if current_text:
                    formatted_transcript.append({
                        'speaker': current_speaker,
                        'text': ' '.join(current_text).strip()
                    })
                current_speaker = speaker
                current_text = [text]
            else:
                current_text.append(text)
        
        if current_text:
            formatted_transcript.append({
                'speaker': current_speaker,
                'text': ' '.join(current_text).strip()
            })
    
        return formatted_transcript

    def format_transcript_with_speakers(self, speaker_transcript):
        """
        Format transcript with speaker labels for display
        """
        formatted = []
        
        for segment in speaker_transcript:
            speaker = segment.get('speaker', 'UNKNOWN')
            text = segment.get('text', '')
            
            # Format as "Speaker 1: text here"
            formatted.append(f"**{speaker}:** {text}")
        
        return '\n\n'.join(formatted)


# Singleton pipeline instance
pipeline = TranscribeFlowPipeline()
schemas.py 
from pydantic import BaseModel, EmailStr
from typing import Optional, List
from datetime import datetime

# =====================================================
# User Schemas
# =====================================================

class UserBase(BaseModel):
    email: EmailStr
    name: Optional[str] = None

class UserCreate(BaseModel):
    username: str
    email: EmailStr
    password: str  # âœ… Plain password (will be hashed)
    name: Optional[str] = None

class UserLogin(BaseModel):
    username: str
    password: str

class UserResponse(BaseModel):
    id: str
    username: str
    email: EmailStr
    name: Optional[str] = None
    created_at: datetime
    total_files: int
    total_minutes: float
    
    class Config:
        from_attributes = True

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    user_id: Optional[str] = None


# File Schemas
class FileBase(BaseModel):
    filename: str
    file_size_mb: Optional[float] = None
    language: Optional[str] = None

class FileCreate(FileBase):
    user_id: str
    saved_as: str
    transcript: Optional[str] = None
    summary: Optional[str] = None
    audio_url: Optional[str] = None
    word_timestamps: Optional[str] = None
    speaker_segments: Optional[str] = None

class FileResponse(FileBase):
    id: str
    user_id: str
    saved_as: str
    transcript: Optional[str] = None
    summary: Optional[str] = None
    audio_url: Optional[str] = None
    created_at: datetime
    word_timestamps: Optional[str] = None
    speaker_segments: Optional[str] = None
    
    class Config:
        from_attributes = True


# Statistics Schema
class UserStatsResponse(BaseModel):
    total_files: int
    total_minutes: float
    recent_files_count: int
    account_created: datetime
    word_timestamps: Optional[str] = None
security.py 
import os
import hashlib
import secrets
from datetime import datetime, timedelta
from typing import Optional
from jose import JWTError, jwt
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.orm import Session
from dotenv import load_dotenv

load_dotenv()

# JWT configuration
SECRET_KEY = os.getenv("JWT_SECRET_KEY")
ALGORITHM = os.getenv("JWT_ALGORITHM", "HS256")
ACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", 30))

# OAuth2 scheme for token extraction
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="api/auth/login")

# =====================================================
# Password Hashing Functions (Using PBKDF2)
# =====================================================

def hash_password(password: str) -> str:
    """Hash a password using PBKDF2-SHA256"""
    # Generate a random salt
    salt = secrets.token_bytes(32)
    
    # Hash the password
    pwd_hash = hashlib.pbkdf2_hmac(
        'sha256',
        password.encode('utf-8'),
        salt,
        100000  # iterations
    )
    
    # Return salt + hash as hex string
    return salt.hex() + pwd_hash.hex()

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """Verify a password against its hash"""
    try:
        # Extract salt (first 64 chars = 32 bytes in hex)
        salt = bytes.fromhex(hashed_password[:64])
        stored_hash = hashed_password[64:]
        
        # Hash the provided password with the same salt
        pwd_hash = hashlib.pbkdf2_hmac(
            'sha256',
            plain_password.encode('utf-8'),
            salt,
            100000
        )
        
        # Compare hashes
        return pwd_hash.hex() == stored_hash
    except Exception as e:
        print(f"Password verification error: {e}")
        return False

# =====================================================
# JWT Token Functions
# =====================================================

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """Create a JWT access token"""
    to_encode = data.copy()
    
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    
    return encoded_jwt

def verify_token(token: str) -> dict:
    """Verify and decode JWT token"""
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        return payload
    except JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

# =====================================================
# Token Dependency
# =====================================================

def get_current_user_from_token(token: str = Depends(oauth2_scheme)):
    """Extract user info from JWT token"""
    payload = verify_token(token)
    user_id: str = payload.get("sub")
    
    if user_id is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    return user_id
__init__.py 


